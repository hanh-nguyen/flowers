{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c869d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions, ResNet50\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense, Lambda, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils, load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2abda920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d78466",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bba32fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np_utils.to_categorical(np.array(data['target']), 102)\n",
    "    return files, targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('./Data/Datasplit/train')\n",
    "valid_files, valid_targets = load_dataset('./Data/Datasplit/valid')\n",
    "test_files, test_targets = load_dataset('./Data/Datasplit/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "753a986d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020, 102)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fe5f58",
   "metadata": {},
   "source": [
    "## Convert images to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f21673df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)      \n",
    "    img = np.expand_dims(img, axis=0)  # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9649574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1020/1020 [00:07<00:00, 145.52it/s]\n",
      "100%|██████████████████████████████████████| 1020/1020 [00:06<00:00, 146.57it/s]\n",
      "100%|███████████████████████████████████████| 6149/6149 [01:03<00:00, 96.58it/s]\n"
     ]
    }
   ],
   "source": [
    "train_tensors = paths_to_tensor(train_files)\n",
    "valid_tensors = paths_to_tensor(valid_files)\n",
    "test_tensors = paths_to_tensor(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8ff4ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1020, 224, 224, 3), (6149, 224, 224, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensors.shape, valid_tensors.shape, test_tensors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd8474e",
   "metadata": {},
   "source": [
    "## Use Resnet50 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b7e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "#Loading the ResNet50 model with pre-trained ImageNet weights\n",
    "resnet = tf.keras.applications.ResNet50(weights='imagenet',include_top=False,input_tensor=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12013846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resnet.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea871b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in resnet.layers[:170]: layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c6f16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: tf.image.resize(x,(224, 224))))\n",
    "model.add(resnet)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(102, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e434def4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e1161cf10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4), \n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_tensors, train_targets, batch_size=32, epochs=10, verbose=0, \n",
    "          validation_data=(valid_tensors, valid_targets), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b88cee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 116s 4s/step - loss: 3.3539 - accuracy: 0.5804\n",
      "32/32 [==============================] - 119s 4s/step - loss: 3.8533 - accuracy: 0.3010\n",
      "193/193 [==============================] - 688s 4s/step - loss: 3.9579 - accuracy: 0.2415\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(train_tensors, train_targets)\n",
    "model.evaluate(valid_tensors, valid_targets)\n",
    "model.evaluate(test_tensors, test_targets);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c0fab3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 24.1503%\n"
     ]
    }
   ],
   "source": [
    "flower_preds = [np.argmax(model.predict(np.expand_dims(tensor, axis=0), verbose=0)) for tensor in test_tensors]\n",
    "test_accuracy = 100*np.sum(np.array(flower_preds)==np.argmax(test_targets, axis=1))/len(flower_preds)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152cf197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flowers",
   "language": "python",
   "name": "flowers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
